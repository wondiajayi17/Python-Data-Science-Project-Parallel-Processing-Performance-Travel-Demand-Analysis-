# Parallel-Processing-Performance-Travel-Demand-Analysis-Python-Data-Science-Project-

This repository contains a data science coursework project focused on analysing large-scale travel demand data and evaluating the impact of parallel processing on data analysis performance.

The project combines performance benchmarking with applied data analysis to explore how different numbers of processors affect execution time, alongside an exploratory and descriptive analysis of real trip data by distance category and date.

The notebooks demonstrate an end-to-end analytical workflow including data loading, preprocessing, aggregation and visualisation using Python.

Key components of the project include:
- Performance benchmarking of analytical workloads using different processor counts (e.g. 8 and 10 processors)
- Comparison of execution time across multiple experimental runs
- Visual analysis of processing stability and scalability
- Exploration of trip volumes across multiple distance ranges
- Daily trend analysis for selected distance categories (e.g. 10–25 miles and 50–100 miles)
- Aggregation and comparison of total trips by distance band
- Visual reporting using line charts and bar charts

Datasets include:
- Full trip-level data
- Aggregated trip counts by distance category
- This project demonstrates practical skills in:
- Data cleaning and transformation
- Performance evaluation of parallel computing approaches
- Exploratory data analysis
- Data visualisation for large datasets
- Reproducible analysis using Jupyter Notebooks and Python

Tools and technologies:
- Python
- pandas and NumPy
- matplotlib
- Jupyter Notebook

The repository is structured to show incremental development through multiple notebooks, with a final consolidated notebook presenting the completed analysis and results.
